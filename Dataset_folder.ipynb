{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJs03ShYlyin"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import download_img\n",
    "\n",
    "import urllib.request as req\n",
    "# set files and dir\n",
    "CSV_PATH, OUT_DIR = 'train.csv', 'train'  # recognition challenge\n",
    "# CSV_PATH, OUT_DIR = '../input/index.csv', '../input/index'  # retrieval challenge\n",
    "# CSV_PATH, OUT_DIR = '../input/test.csv', '../input/test'  # test data\n",
    "\n",
    "# preferences\n",
    "TARGET_SIZE = 96  # image resolution to be stored\n",
    "IMG_QUALITY = 90  # JPG quality\n",
    "NUM_WORKERS = 8  # Num of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Z1QHEUnSr9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def overwrite_urls(df):\n",
    "    def reso_overwrite(url_tail):\n",
    "        pattern = 's[0-9]+'\n",
    "        search_result = re.match(pattern, url_tail)\n",
    "        if search_result is None:\n",
    "            return url_tail\n",
    "        else:\n",
    "            return 's{}'.format(TARGET_SIZE)\n",
    "\n",
    "    def join_url(parsed_url, s_reso):\n",
    "        parsed_url[-2] = s_reso\n",
    "        return '/'.join(parsed_url)\n",
    "\n",
    "    parsed_url = df.url.apply(lambda x: x.split('/'))\n",
    "    train_url_tail = parsed_url.apply(lambda x: x[-2])\n",
    "    resos = train_url_tail.apply(lambda x: reso_overwrite(x))\n",
    "\n",
    "    overwritten_df = pd.concat([parsed_url, resos], axis=1)\n",
    "    overwritten_df.columns = ['url', 's_reso']\n",
    "    df['url'] = overwritten_df.apply(lambda x: join_url(x['url'], x['s_reso']), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_data(df):\n",
    "    key_url_list = [line[:3] for line in df.values]\n",
    "    return key_url_list\n",
    "\n",
    "\n",
    "def download_image(key_url):\n",
    "    (key, url,lid) = key_url\n",
    "    lid=str(lid) \n",
    "    fold=os.path.join(OUT_DIR,lid) \n",
    "    if not os.path.exists(fold):\n",
    "        os.mkdir(fold)\n",
    "    print(fold)\n",
    "    filename = os.path.join(fold, '{}.jpg'.format(key))\n",
    "   \n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        print('Image {} already exists. Skipping download.'.format(filename))\n",
    "        return 0\n",
    "\n",
    "    try:\n",
    "        response = request.urlopen(url)\n",
    "        image_data = response.read()\n",
    "    except:\n",
    "        print('Warning: Could not download image {} from {}'.format(key, url))\n",
    "        return 1\n",
    "\n",
    "    try:\n",
    "        pil_image = Image.open(BytesIO(image_data))\n",
    "    except:\n",
    "        print('Warning: Failed to parse image {}'.format(key))\n",
    "        return 1\n",
    "\n",
    "    try:\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "    except:\n",
    "        print('Warning: Failed to convert image {} to RGB'.format(key))\n",
    "        return 1\n",
    "\n",
    "    try:\n",
    "        pil_image = pil_image.resize((TARGET_SIZE, TARGET_SIZE))\n",
    "    except:\n",
    "        print('Warning: Failed to resize image {}'.format(key))\n",
    "        return 1\n",
    "\n",
    "    try:\n",
    "        pil_image.save(filename, format='JPEG', quality=IMG_QUALITY)\n",
    "    except:\n",
    "        print('Warning: Failed to save image {}'.format(filename))\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loader(df):\n",
    "    if not os.path.exists(OUT_DIR):\n",
    "        os.mkdir(OUT_DIR)\n",
    "\n",
    "    key_url_list = parse_data(df)\n",
    "    pool = multiprocessing.Pool(processes=NUM_WORKERS)\n",
    "    failures = sum(tqdm.tqdm(pool.imap_unordered(download_img.download_image, key_url_list),\n",
    "                             total=len(key_url_list)))\n",
    "    print('Total number of download failures:', failures)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250372
    },
    "colab_type": "code",
    "id": "8-EixrzZn2Xs",
    "outputId": "5cfb8b20-7632-498c-99a2-39c58bdbc664",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "  2%|█▏                                                                     | 17407/1035631 [28:47<63:31:47,  4.45it/s]"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] Cannot create a file when that file already exists: 'train\\\\315'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Prakhar\\Miniconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Prakhar\\Desktop\\test_for_tqdm\\download_img.py\", line 24, in download_image\n    os.mkdir(fold)\nFileExistsError: [WinError 183] Cannot create a file when that file already exists: 'train\\\\315'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-75347149e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'url != \"None\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverwrite_urls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-6e0595c7ed4a>\u001b[0m in \u001b[0;36mloader\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     failures = sum(tqdm.tqdm(pool.imap_unordered(download_img.download_image, key_url_list),\n\u001b[1;32m---> 87\u001b[1;33m                              total=len(key_url_list)))\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total number of download failures:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [Errno 17] Cannot create a file when that file already exists: 'train\\\\315'"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(CSV_PATH).query('url != \"None\"')\n",
    "    loader(overwrite_urls(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IW4nC5bSrrXx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mkAoNg2Zs9r3",
    "outputId": "efbd80d2-0ae0-4bea-aab0-d7f83ca57bf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "colab_type": "code",
    "id": "Vu61P4_jtWx3",
    "outputId": "486933f7-50dc-4244-f09c-56f439d025f0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmMNKJGqvLyc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
